{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0f8d29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\diwak\\anaconda3\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\diwak\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c2d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b1aa9",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f3c4f",
   "metadata": {},
   "source": [
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564b3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connecting to driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275a7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening naukri.com page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe238715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation automated \n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cb596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location automated\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div[1]/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e6bbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button automated\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div[1]/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770a5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94343caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job_location from given page  \n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping company_name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping experience_required from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4fa29a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),\n",
    "      len(job_location),\n",
    "          len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "164bfdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - Pharma/hls Domain (4-9 Years)</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Gurgaon/Gur...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst- Yulu Energy</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yulu Bikes</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Entrupy</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>What Digital Technologies</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst Databricks</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Aon</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Group</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Required Data Analyst Off Role</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst | Google App Script</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Webengage</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job_title  \\\n",
       "0  Data Analyst - Pharma/hls Domain (4-9 Years)   \n",
       "1                     Data Analyst- Yulu Energy   \n",
       "2                                  Data Analyst   \n",
       "3                                  Data Analyst   \n",
       "4                       Data Analyst Databricks   \n",
       "5                                  Data Analyst   \n",
       "6                                  Data Analyst   \n",
       "7                                  Data Analyst   \n",
       "8                Required Data Analyst Off Role   \n",
       "9              Data Analyst | Google App Script   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Mumbai, Pune, Gurgaon/Gur...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6          Hybrid - Bangalore/Bengaluru, Delhi / NCR   \n",
       "7                       Hybrid - Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                        Bangalore/Bengaluru, Mumbai   \n",
       "\n",
       "                Company_name Exp_required  \n",
       "0          Fractal Analytics    10-20 Yrs  \n",
       "1                 Yulu Bikes      0-1 Yrs  \n",
       "2                    Entrupy      1-3 Yrs  \n",
       "3  What Digital Technologies     5-10 Yrs  \n",
       "4                      Optum      4-6 Yrs  \n",
       "5                    Siemens      1-4 Yrs  \n",
       "6                        Aon      6-9 Yrs  \n",
       "7              Allegis Group      4-7 Yrs  \n",
       "8                  TeamLease      3-5 Yrs  \n",
       "9                  Webengage      3-6 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4f8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d11c6",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7f862",
   "metadata": {},
   "source": [
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "    location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09170531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04578b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connecting to driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fcf5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening naukri.com page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "697b9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation automated \n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06de6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location automated\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b78f4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0b1c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e91347bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job_location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping company_name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "456b8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location), len(company_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fa8c05d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...</td>\n",
       "      <td>Cognizant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, M...</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>Capgemini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Birlasoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>UPL Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Indore, Pune, Gurg...</td>\n",
       "      <td>Impetus Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Artificial Intelligence Specialist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job_title  \\\n",
       "0                  Data Science Specialist   \n",
       "1         Analystics & Modeling Specialist   \n",
       "2                           Data Scientist   \n",
       "3                     Staff Data Scientist   \n",
       "4                       Sr. Data scientist   \n",
       "5                           Data Scientist   \n",
       "6                      Lead Data Scientist   \n",
       "7                    Expert Data Scientist   \n",
       "8                           Data Scientist   \n",
       "9  Lead Artificial Intelligence Specialist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...   \n",
       "3                        Bangalore/Bengaluru, Mumbai   \n",
       "4  Bangalore/Bengaluru, Hyderabad/Secunderabad, M...   \n",
       "5  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...   \n",
       "6  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "7                        Bangalore/Bengaluru, Mumbai   \n",
       "8  Bangalore/Bengaluru, Noida, Indore, Pune, Gurg...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                      Company_name  \n",
       "0                        Accenture  \n",
       "1                        Accenture  \n",
       "2                        Cognizant  \n",
       "3                     Baker Hughes  \n",
       "4  Tata Consultancy Services (TCS)  \n",
       "5                        Capgemini  \n",
       "6                        Birlasoft  \n",
       "7                      UPL Limited  \n",
       "8             Impetus Technologies  \n",
       "9                     Baker Hughes  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1330e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0389bb2",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9a5c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3452503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a4a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening naukri.com page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f07e7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation automated \n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee077969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search clicking automated\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e45abe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location filter \n",
    "location_Delhi=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/i\")\n",
    "location_Delhi.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f9169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary filter 3-6 lakhs\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d4a8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for required data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f72431e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job-title, job-location, company name, experience required from given page\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bc61f02",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist data Analyst</td>\n",
       "      <td>Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Smark Laser Automation</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - Statistics</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Noida(Sector-136 Noida), Ghaziaba...</td>\n",
       "      <td>Extramarks Education</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Gartner India Research &amp;amp; Advisory Services...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Scientist - ML &amp; NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Gartner India Research &amp;amp; Advisory Services...</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Delhi / NCR, Noida, New Delhi, Gurgao...</td>\n",
       "      <td>Nits Solutions</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job_title  \\\n",
       "0          Data Scientist data Analyst   \n",
       "1    Data Scientist - Engine Algorithm   \n",
       "2                 Analyst-Data Science   \n",
       "3                 Analyst-Data Science   \n",
       "4   Senior Data Scientist - Statistics   \n",
       "5                       Data Scientist   \n",
       "6                       Data Scientist   \n",
       "7  Associate Data Scientist - ML & NLP   \n",
       "8                       Data Scientist   \n",
       "9                       Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...   \n",
       "1  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5  Delhi / NCR, Noida(Sector-136 Noida), Ghaziaba...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8  Hybrid - Delhi / NCR, Noida, New Delhi, Gurgao...   \n",
       "9                                              Noida   \n",
       "\n",
       "                                        Company_name Experience_required  \n",
       "0                             Smark Laser Automation             0-5 Yrs  \n",
       "1                                       Primo Hiring             1-3 Yrs  \n",
       "2                                   AMERICAN EXPRESS             0-3 Yrs  \n",
       "3                                   AMERICAN EXPRESS             0-3 Yrs  \n",
       "4                                              Optum             5-8 Yrs  \n",
       "5                               Extramarks Education             3-5 Yrs  \n",
       "6  Gartner India Research &amp; Advisory Services...             2-7 Yrs  \n",
       "7  Gartner India Research &amp; Advisory Services...             2-4 Yrs  \n",
       "8                                     Nits Solutions             3-7 Yrs  \n",
       "9                            Gujarat Fluorochemicals             1-2 Yrs  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Experience_required':experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eba77064",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc286e",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "064f8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7de9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening flipkart.com page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e190773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing login pop up automated\n",
    "cross=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\") \n",
    "cross.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbc82548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching sunglasses automated\n",
    "\n",
    "sunglasses=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "sunglasses.send_keys('sunglasses')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea467a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6467c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping-we will take data for 3 pages as 1 page show 40 result & we require 100\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brands=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brands[0:100]:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    prod_desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in prod_desc[0:100]:\n",
    "        product_description.append(i.text)    \n",
    "    \n",
    "    prices=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in prices[0:100]:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8ed2644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b81ddfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection, Riding Glasses Retro Square, Re...</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (58)</td>\n",
       "      <td>₹99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product_description Price\n",
       "0       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  ₹149\n",
       "1            SRPM             UV Protection Wayfarer Sunglasses (50)  ₹149\n",
       "2          PIRASO              UV Protection Aviator Sunglasses (58)  ₹274\n",
       "3    Singco India  UV Protection, Riding Glasses Retro Square, Re...  ₹599\n",
       "4        Fastrack       UV Protection Aviator Sunglasses (Free Size)  ₹633\n",
       "..            ...                                                ...   ...\n",
       "95  VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹829\n",
       "96         PIRASO              UV Protection Aviator Sunglasses (54)  ₹208\n",
       "97      Elligator                UV Protection Round Sunglasses (54)  ₹293\n",
       "98          NuVew   UV Protection, Mirrored Wayfarer Sunglasses (58)   ₹99\n",
       "99   Singco India  Gradient, Toughened Glass Lens, UV Protection ...  ₹664\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Brand':brand[0:100],'Product_description':product_description[0:100],'Price':price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca7a86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a611a88",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9fda8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "325510a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening review page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "309e556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_short=[]\n",
    "full_review=[]\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b6d771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will take data for 10 pages as 1 page show 10 result & we require 100\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in ratings[0:100]:\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    reviewshort=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in reviewshort[0:100]:\n",
    "        review_short.append(i.text)    \n",
    "    \n",
    "    fullreview=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in fullreview[0:100]:\n",
    "        full_review.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8f0ca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_short),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbb5dd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       4      Value-for-money   \n",
       "4       5   Highly recommended   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5     Perfect product!   \n",
       "97      5   Highly recommended   \n",
       "98      4          Pretty good   \n",
       "99      5        Great product   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Value for money\\n5 star rating\\nExcellent came...  \n",
       "97  What a camera .....just awesome ..you can feel...  \n",
       "98  I was using Iphone 6s and also Oneplus 6t. Bot...  \n",
       "99  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rating':rating,'Review summary':review_short,'Full review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7919c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0ac00",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d879ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a1a3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a45f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing login pop up automated\n",
    "cross=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\") \n",
    "cross.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4af0b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching sneakers automated\n",
    "writesneakers=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "writesneakers.send_keys(\"sneakers\")\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e8d636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3869ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping-we will take data for 3 pages as 1 page show 40 result & we require 100\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brands=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brands[0:100]:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    prod_desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in prod_desc[0:100]:\n",
    "        product_description.append(i.text)    \n",
    "    \n",
    "    prices=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in prices[0:100]:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4253dc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2995763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>BALANCER Men's Fashion Sneakers Lace-Up Traine...</td>\n",
       "      <td>₹1,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Mesh| Ultralightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                Product_description   Price\n",
       "0          aadi  Synthetic Leather |Lightweight|Comfort|Summer|...    ₹399\n",
       "1            TR                                   Sneakers For Men    ₹331\n",
       "2         BIRDE                                 Sneakers For Women    ₹199\n",
       "3           SFR                                   Sneakers For Men    ₹298\n",
       "4          aadi  Synthetic Leather |Lightweight|Comfort|Summer|...    ₹299\n",
       "..          ...                                                ...     ...\n",
       "95         aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ₹599\n",
       "96       BRUTON             2 Combo Sneaker Shoes Sneakers For Men    ₹499\n",
       "97  bacca bucci  BALANCER Men's Fashion Sneakers Lace-Up Traine...  ₹1,499\n",
       "98        BIRDE      Combo Pack of 2 Casual Shoes Sneakers For Men    ₹499\n",
       "99         aadi  Mesh| Ultralightweight| Premiun| Comfort| Summ...    ₹399\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Brand':brand[0:100],'Product_description':product_description[0:100],'Price':price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ecff74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc45615",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8997324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5413386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening amazon.in page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed02193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing and searching laptop automated\n",
    "laptop=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "laptop.send_keys('Laptop')\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98b44d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter i7 cpu automated\n",
    "ticki7=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[6]/li[11]/span/a/div/label/i')\n",
    "ticki7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0aafa36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ebcb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data for Title, Ratings, Price\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,\"//div[@class='a-section a-spacing-none puis-padding-right-small s-title-instructions-style']\")\n",
    "for i in title_tags[0:10]:\n",
    "    titles=i.text\n",
    "    Title.append(titles)\n",
    "    \n",
    "rating_tags=driver.find_elements(By.XPATH,\"//span[@class='a-size-base']\")\n",
    "for i in rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    Ratings.append(rating)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in price_tags[0:10]:\n",
    "    prices=i.text\n",
    "    Price.append(prices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78d7ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c43ebfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 14, Intel Core i7-1165G7 11th Ge...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>56,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>65,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 Intel Core i7 6t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14 11th Gen Intel Core i7 16GB/1TB...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>92,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,49,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkPad P14s Mobile Workstation 11th G...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,03,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop 5400 Intel Core...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop 5400 Intel Core...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>31,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  ASUS Vivobook 14, Intel Core i7-1165G7 11th Ge...     4.1    56,990\n",
       "1  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...     4.1    65,250\n",
       "2  (Renewed) Dell Latitude E7470 Intel Core i7 6t...     4.0    30,074\n",
       "3  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...     4.2    82,990\n",
       "4  HP Pavilion 14 11th Gen Intel Core i7 16GB/1TB...     4.4    92,500\n",
       "5  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...     4.0    94,490\n",
       "6  ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...     5.0  1,49,610\n",
       "7  Lenovo ThinkPad P14s Mobile Workstation 11th G...     5.0  1,03,990\n",
       "8  (Renewed) Dell Latitude Laptop 5400 Intel Core...     3.3    35,990\n",
       "9  (Renewed) Dell Latitude Laptop 5400 Intel Core...     3.7    31,990"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':Title,'Ratings':Ratings,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb0508c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b84651",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on Top Quotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50b48e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c4b661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening azquotes.com page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eebc902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7ee991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote=[]\n",
    "Author=[]\n",
    "TypeOfQuotes=[]\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c483d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping-we will take data for 10 pages as 1 page show 100 result & we require all 1000\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    quotes=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quotes:\n",
    "        Quote.append(i.text)\n",
    "    \n",
    "    authors=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in authors:\n",
    "        Author.append(i.text)    \n",
    "    \n",
    "    quote_type=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in quote_type:\n",
    "        TypeOfQuotes.append(i.text)\n",
    "    next_button=driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f0c5b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote),len(Author),len(TypeOfQuotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09d80a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes                Author  \\\n",
       "0    The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                 ...                   ...   \n",
       "995     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "996  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "997  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "998  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "999    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                                Type of quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995                    Music, Sports, Hunting  \n",
       "996             Trust, Encouraging, Uplifting  \n",
       "997              Inspirational, Funny, Change  \n",
       "998                      Success, God, Mother  \n",
       "999       Inspirational, Motivational, Change  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Quotes':Quote,'Author':Author,'Type of quote':TypeOfQuotes })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fcb4daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3bf91",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b52b8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd50ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening www.jagranjosh.com/ page on automated chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f9668719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click gk button\n",
    "GKbutton=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "GKbutton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be2c232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the List of all Prime Ministers of India\n",
    "PM_list=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "PM_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f42baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name= []\n",
    "Born_Dead = []\n",
    "Terms_of_office = []\n",
    "Remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "71bcb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping name\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "for name in names:\n",
    "    Name.append(name.text)\n",
    "    \n",
    "\n",
    "# scraping borndead\n",
    "born_dead = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for i in born_dead:\n",
    "    Born_Dead.append(i.text)\n",
    "    \n",
    "\n",
    "# scraping terms_of_office\n",
    "terms_of_office = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[4]')\n",
    "for i in terms_of_office:\n",
    "    Terms_of_office.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "    \n",
    "# scraping Remarks\n",
    "remarks = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for i in remarks:\n",
    "    Remarks.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b3b37658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18 18\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Born_Dead),len(Terms_of_office),len(Remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06dd1968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 196416 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 19661 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 196613 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 197711 years, 59 days</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 19844 years, 291...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 19895 years, 32 ...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 19964 years, 330 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 199616 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Names     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term of office  \\\n",
       "0     15 August 1947 to 27 May 196416 years, 286 days   \n",
       "1                  27 May 1964 to 9 June 1964,13 days   \n",
       "2      9 June 1964 to 11 January 19661 year, 216 days   \n",
       "3           11 January 1966 to 24 January 196613 days   \n",
       "4   24 January 1966 to 24 March 197711 years, 59 days   \n",
       "5     24 March 1977 to  28 July 1979 2 year, 126 days   \n",
       "6             28 July 1979 to 14 January 1980170 days   \n",
       "7   14 January 1980 to 31 October 19844 years, 291...   \n",
       "8   31 October 1984 to 2 December 19895 years, 32 ...   \n",
       "9         2 December 1989 to 10 November 1990343 days   \n",
       "10           10 November 1990 to 21 June 1991223 days   \n",
       "11       21 June 1991 to 16 May 19964 years, 330 days   \n",
       "12                  16 May 1996 to 1 June 199616 days   \n",
       "13               1 June 1996 to 21 April 1997324 days   \n",
       "14            21 April 1997 to 19 March 1998 332 days   \n",
       "15      19 March 1998 to 22 May 2004 6 years, 64 days   \n",
       "16      22 May 2004 to 26 May 2014   10 years, 4 days   \n",
       "17                              26 May 2014 - Present   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Names\":Name,\"Born-Dead\":Born_Dead,\"Term of office\":Terms_of_office,\"Remarks\":Remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5bb41590",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc0673",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on left side.\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69a2507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d32072b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d5f838d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown=driver.find_element(By.XPATH,\"//div[@class='box-item-left']\")\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "baf25c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down2=driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[5]/button\")\n",
    "drop_down2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aaaa0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists=driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a\")\n",
    "lists.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e05e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topexpensive_cars=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div[1]/div[1]/div/div/div[2]/div/div[1]/h3/a\")\n",
    "topexpensive_cars.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c8a0c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=[]\n",
    "Prices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "08b8f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in name_tags[0:50]:\n",
    "    name=i.text\n",
    "    Names.append(name)\n",
    "\n",
    "price_tags=driver.find_elements(By.XPATH,\"//strong\")\n",
    "for i in price_tags[0:50]:\n",
    "    price=i.text\n",
    "    Prices.append(price)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "36548a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(Names),len(Prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "54656081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME OF THE CAR</th>\n",
       "      <th>PRICE OF THE CAR IN ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NAME OF THE CAR PRICE OF THE CAR IN ($)\n",
       "0                     De Tomaso P72     Price: $1.3 Million\n",
       "1                 Ferrari LaFerrari     Price: $1.4 Million\n",
       "2                     Pagani Huayra     Price: $1.4 Million\n",
       "3                      McLaren Elva                        \n",
       "4                       Czinger 21C     Price: $1.7 Million\n",
       "5                     Ferrari Monza     Price: $1.7 Million\n",
       "6                Gordon Murray T.33     Price: $1.7 Million\n",
       "7                 Koenigsegg Gemera     Price: $1.7 Million\n",
       "8                       Zenvo TSR-S     Price: $1.7 Million\n",
       "9                Hennessey Venom F5     Price: $1.7 Million\n",
       "10                  Bentley Bacalar     Price: $1.8 Million\n",
       "11    Hispano Suiza Carmen Boulogne     Price: $1.9 Million\n",
       "12           Bentley Mulliner Batur     Price: $1.9 Million\n",
       "13                     Deus Vayanne     Price: $2.0 Million\n",
       "14                      SSC Tuatara     Price: $2.0 Million\n",
       "15                      Lotus Evija    Price: $2.0 Million*\n",
       "16              Aston Martin Vulcan     Price: $2.1 Million\n",
       "17                       Delage D12     Price: $2.3 Million\n",
       "18                McLaren Speedtail     Price: $2.3 Million\n",
       "19                     Rimac Nevera     Price: $2.3 Million\n",
       "20                    Pagani Utopia     Price: $2.4 Million\n",
       "21             Pininfarina Battista     Price: $2.5 Million\n",
       "22                Ferrari FXX K Evo     Price: $2.5 Million\n",
       "23               Gordon Murray T.50     Price: $2.6 Million\n",
       "24             Lamborghini Countach     Price: $2.6 Million\n",
       "25         Mercedes-AMG Project One     Price: $2.6 Million\n",
       "26              Aston Martin Victor     Price: $2.7 Million\n",
       "27      Hennessey Venom F5 Roadster     Price: $3.0 Million\n",
       "28                 Koenigsegg Jesko            $3.0 Million\n",
       "29            Aston Martin Valkyrie     Price: $3.0 Million\n",
       "30        W Motors Lykan Hypersport     Price: $3.2 Million\n",
       "31                    McLaren Solus     Price: $3.4 Million\n",
       "32        Pagani Huayra Roadster BC            $3.5 Million\n",
       "33         Bugatti Chiron Pur Sport     Price: $3.5 Million\n",
       "34                 Lamborghini Sian     Price: $3.6 Million\n",
       "35                 Koenigsegg CC850     Price: $3.6 million\n",
       "36  Bugatti Chiron Super Sport 300+     Price: $3.7 Million\n",
       "37               Lamborghini Veneno     Price: $3.9 Million\n",
       "38                   Bugatti Bolide     Price: $4.5 Million\n",
       "39                  Bugatti Mistral     Price: $4.7 Million\n",
       "40              Pagani Huayra Imola     Price: $5.0 Million\n",
       "41                     Bugatti Divo     Price: $5.4 Million\n",
       "42              SP Automotive Chaos     Price: $5.8 Million\n",
       "43                 Pagani Codalunga     Price: $6.4 Million\n",
       "44         Mercedes-Maybach Exelero     Price: $7.4 Million\n",
       "45               Bugatti Centodieci     Price: $8.0 Million\n",
       "46          Bugatti Chiron Profilée     Price: $9.0 Million\n",
       "47             Rolls-Royce Sweptail    Price: $10.8 Million\n",
       "48         Bugatti La Voiture Noire    Price: $12.8 Million\n",
       "49           Rolls-Royce Boat Tail*    Price: $13.4 Million"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"NAME OF THE CAR\":Names,\"PRICE OF THE CAR IN ($)\":Prices})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf029a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
